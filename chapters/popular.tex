% ---------------------------------------------------------------------
% ---------------------------------------------------------------------
% ---------------------------------------------------------------------


{\let\cleardoublepage\relax
 \let\clearpage\relax

 \newpage
 
 \chapter*{Populärvetenskaplig sammanfattning}

 \vspace{-1.5cm}

Modern vetenskap och teknik är starkt beroende av avancerade datorsimuleringar för att lösa komplexa problem, till exempel inom klimatmodellering eller flygteknik. Dessa simuleringar kan dock vara extremt beräkningskrävande, särskilt när man måste följa systemets utveckling över lång tid. I denna avhandling utvecklar vi en ny metod för att skapa förenklade modeller som behåller noggrannheten hos de fullskaliga simuleringarna, men med en bråkdel av beräkningskostnaden.

Vår metod kombinerar två kraftfulla matematiska verktyg: en teknik för datadriven modellering (kallad Operator Inference) och en optimeringsmetod baserad på s.k. adjoint-ekvationer. Genom att formulera ett speciellt ``felmått" som mäter avvikelsen över hela tidsintervallet istället för vid enskilda tidpunkter, undviker vi känsliga beräkningar som kan förstärka mätfel i data. Metoden lär sig automatiskt att justera modellparametrarna genom att analysera hur små förändringar påverkar det totala felet, en process som påminner om hur maskininlärningsmodeller tränas, men här anpassad för vetenskapliga simuleringar.

Vi testar metoden på två klassiska exempel från strömningsmekanik och kemisk reaktionsdiffusion. Resultaten visar att vår metod presterar lika bra som befintliga tekniker när datainspelningarna är rena och tätt samplade. Men när vi introducerar realistiskt mätbrus i data, presterar vår metod klart bättre genom att effektivt filtrera bort bruset under inlärningsprocessen. En avgörande fördel är att beräkningskostnaden endast ökar konstant med antalet parametrar, vilket gör metoden särskilt lovande för extremt högdimensionella problem. Dessa resultat öppnar dörren till mer tillförlitliga förenklade modeller i situationer där experimentella data är brusiga eller sparsamt samplade, ett vanligt scenario i praktiska tillämpningar. 
 

\addvspace{1.3cm}

 
 \chapter*{Acknowledgements}
%\chapter*{Tack}

%\begin{quote}
%	\begin{flushright}
%		\textit{Life is like riding a bicycle. To keep your balance, you must keep moving.} \\
		
%		-- \textbf{Albert Einstein} --
%	\end{flushright}
%\end{quote}

% ---------------------------------------------------------------------
% ---------------------------------------------------------------------
% ---------------------------------------------------------------------

\addvspace{-1.5cm}

%\begin{Summary}
%    [Quote].


%\textit{Lund, June 2025} \hfill \textit{Francisco García Atienza}
%\end{Summary}

I would like to express my gratitude to my classmates and professors over these past five years of undergraduate and master’s studies, in no particular order: Claus, Philipp, Robert, Tony, Erik, Anna-Maria, Viktor, Kjell, Anitha, Jan-Fredrik, and many others. From each of you I have learned something unique, and you have all contributed to deepening my passion for mathematics.

A special thanks goes to my supervisor, Mengwu Guo, for his approachability, his invaluable guidance, and for introducing me to the truly fascinating world of Scientific Machine Learning. 

Last but by no means least, I dedicate this thesis to my family. To my six siblings, whom I love with all my heart; to my father, ever in my memory, who taught me the value of humility in education; to my mother, for showing me daily what it means to sacrifice for what you love most; and to my partner throughout this journey, Alfredo, for his unconditional love through both good times and bad. Your support has been my greatest strength.


%\vspace*{2cm}
}